# Standards Ingest Product Requirements Document (PRD)

## 1. Executive Summary

We are extending an existing code review system to support ingestion and management of multiple standards sets—collections of individual standards—for code quality checks. The system will allow users to:

1. Upload and manage **Standards Sets** and **Classifications** (metadata about technologies/languages)
2. Dynamically match code repositories against the standards relevant to the repository's technology stack
3. Provide integrated **frontend pages** and **backend API endpoints** for managing standards, classifications, and code reviews

These features build on an existing Python-based API (FastAPI) that leverages Anthropic's Claude AI model and MongoDB for persistence, and a Node.js/Hapi.js-based GOV.UK Design System (GDS)-compliant frontend.

## 2. Background

### 2.1 Existing System Overview

#### 2.1.1 Core Functionality (Current)
* **Accept Code Submissions** for review
* **Process submissions asynchronously** using AI agents
* **Check code against multiple predefined standards**
* **Store review results** in MongoDB
* **Provide RESTful API endpoints** to retrieve and manage code review results

Currently, the system is configured with a **hard-coded** set of standards.

#### 2.1.2 API Backend
* **Language/Framework**: Python, FastAPI
* **AI Model**: Anthropic's Claude for intelligent code analysis
* **Database**: MongoDB for persistence
* **Architecture**:
  * Modular structure with FastAPI's dependency injection
  * Robust logging, strict typing, and comprehensive tests
  * Enforces code quality with Pylint and Pyright

#### 2.1.3 Frontend
* **Language/Framework**: Node.js with Hapi.js
* **Design**: GOV.UK Design System (GDS) with SCSS for styling
* **Rendering**: Nunjucks templating, server-side rendering
* **Tooling**: Webpack, Babel, TypeScript, Jest, ESLint, Prettier
* **Current Features**:
  * A home page for repository submission
  * Health check endpoints
  * Error handling pages
  * Basic routing for future expansion

## 3. Problem Statement & Goals

### 3.1 Problem Statement

* Currently, the code review system only supports a single, hard-coded set of standards
* We need the ability to ingest **any** standards from remote repositories and store them in the database
* We must implement a **Classification Manager** to match code repositories with relevant standards based on technology stacks

### 3.2 Goals

1. **Flexible Standards Ingestion**: Allow users to upload new standard sets and automatically parse them into individual standards
2. **Classification-Based Matching**: Implement a classification system to label standards (e.g., "Python," "Node.js," ".NET") and automatically match code repositories to relevant standards
3. **Enhanced Reporting**: Adapt the existing code review process to incorporate multiple standard sets, each with its own custom LLM prompt
4. **Frontend Management**: Provide user interfaces to manage classifications, standards, and standard sets in alignment with GDS guidelines

## 4. High-Level Solution Overview

1. **Classification Manager**
   * Backend to manage classifications (create, list, delete)
   * Frontend pages to create/delete classifications
   * Allows grouping of technologies/languages in code repositories

2. **Standards Ingest**
   * Ingest a "standards repository" from a user-provided URL
   * Parse the repository using an LLM agent, create or replace a "standard-set," and store individual "standards" in the database
   * Each standard can be associated with zero or more classifications

3. **Updated Code Review Flow**
   * On code review submission, the system downloads the repository, merges the code, and uses an LLM to identify which classifications apply to the codebase
   * Based on the classifications that match the codebase stack, the system filters relevant standards from each selected standard set
   * The relevant standards are then passed to the reporting agent for analysis

4. **Frontend Enhancements**
   * New pages to manage standard sets and classifications
   * Modified home page to show multiple standard sets for selection
   * Code review detail pages that tabulate reports by standard set

## 5. Detailed Requirements

### 5.1 Classification Manager (✅ Feature Completed)

#### 5.1.1 Backend Requirements
1. **Database Schema**
   * New collection/table: `classifications`
   * Each `classification` record includes:
     * `_id` (automatically generated by MongoDB)
     * `name` (string, unique)

2. **API Endpoints** (`/api/v1/classifications`):
   * **POST** `/api/v1/classifications`
     * Creates a new classification in the database
     * Request Body:
       ```json
       {
         "name": "Node.js"
       }
       ```
     * Response:
       ```json
       {
         "_id": "auto-generated-id",
         "name": "Node.js"
       }
       ```
   * **GET** `/api/v1/classifications`
     * Returns all classifications in alphabetical order
   * **DELETE** `/api/v1/classifications/{id}`
     * Deletes the specified classification
     * Must also remove any references to this classification from any "standards" documents

#### 5.1.2 Frontend Requirements
1. **New Navigation Item**: "Manage Classifications"
2. **Manage Classifications Page**
   * **List** all existing classifications (table view)
   * **Add** a new classification (form that calls `POST /api/v1/classifications`)
   * **Delete** a classification (action that calls `DELETE /api/v1/classifications/{id}`)
   * Show a **warning** message that adding or deleting classifications requires re-ingestion of existing standard sets to update classification relationships

#### 5.1.3 Example Classifications
```
Python, C#, Node.js, JavaScript, Java, .NET
```

### 5.2 Standards Ingest (✅ Feature Completed)

#### 5.2.1 Terminology
* **Code Repository**: The repository to be reviewed
* **Standard-Set**: A parent object that groups multiple individual standards. Contains:
  * `_id`, `name`, `repository_url`, `custom_prompt`
* **Standards**: Individual entries within a standard-set. Contains:
  * `_id`, `text`, `repository_path`, relation to `classifications`
* **Classifications**: Technology identifiers that help categorize standards (e.g., `Python`)

#### 5.2.2 Backend Requirements
1. **Database Schema**
   * **Standard-Sets** Collection
     * `_id`, `name`, `repository_url`, `custom_prompt`
   * **Standards** Collection
     * `_id`, `text`, `repository_path`, `standard_set_id`, `classifications[]`

2. **Relationships**
   * **One-to-Many**: One standard-set to many standards
   * **Many-to-Many**: Many standards to many classifications (implemented by storing classification IDs in the `classifications[]` array within the standard document)

3. **API Endpoints**
   * **`/api/v1/standard-sets`**
     * **POST** `/api/v1/standard-sets`
       1. Check if a standard-set with the same `name` exists. If so, delete the existing one and all its associated standards
       2. Create a new standard-set record
       3. Immediately return newly created standard-set with its `_id`
       4. The following steps will be processed async.  (follow the same ' multiprocessing import Process' async approach we used for the /api/v1/code-reviews POST endpoint):
	       4.1 Download the repository from the provided `repository_url` to a temporary folder (note that we already have a `git_repos_agent` that can download a repository)
	       4.2 Get the full set of `classifications` from the database to use later during our standard analysis LLM call.
	       4.3 Loop over each file in the repository and perform the following:
		       1. Using an Anthropic LLM agent, look for individual standards within the files (could be multiple standards within each file) and determine relevant classifications from the text (classifications can be passed into the prompt from step 2 above)
		       2. If no classifications apply, the standard is "universal" and can apply to any codebase.
		       3. Make an assessment if the standard is "universal" or not before considering adding classifications, because if it's "universal", then no classifications are required.
		       4. For each discovered standard, create a new record in the `standards` collection, associating it with the newly created standard-set
	       4.4 Cleanup temporary folder where the standard-set repository was downloaded
     * **GET** `/api/v1/standard-sets`
       * Returns a list of standard-set objects (without their associated standards)
     * **GET** `/api/v1/standard-sets/{id}`
       * Returns one standard-set object including an array of all associated standards
     * **DELETE** `/api/v1/standard-sets/{id}`
       * Deletes the standard-set and all associated standards (and their references to classifications)

## 5.3 Use standard sets in the existing code review flow (✅ Feature Completed)

This feature makes changes to the existing POST API  `/api/v1/code-reviews` and its async processing. Instead of downloading standards from a file, read standard sets and standards from the database. 

5.3.1. **Request Payload**
   * Must now include an array of standard-set IDs to specify which sets to check against
   ```json
   {
     "repository_url": "https://github.com/DEFRA/find-ffa-data-ingester",
     "standard_sets": ["xyz123", "abc123"]
   }
   ```

5.3.2 **Change existing async processing**

Changing the existing async process in the following ways:
1. Use the standard_sets parameter to get the standard sets from the database
3. Loop over each standard set and check the repository_url against the standards in each standard set
4. Save a separate Markdown report file per standard-set in the format: `{code-review-record-id}-{standard-set-name}.md`
5. Store references to these new report files in the `code-reviews` record. This will be an array with a record for each standard set. 

## 5.4 **Update GET code-reviews API Response & Storage**  (✅ Feature Completed)
The `GET /api/v1/code-reviews/{id}` endpoint should be extended to add the array of reports that are generated

Note that the `GET /api/v1/code-reviews` API should remain the same. i.e. this is a different response model now

## 5.5 Add classifications to code review flow
The feature changes the existing async agentic processing of codebases, adding classifications. This also builds on the functionality in 5.3. 

 This will involve creating a new "Standards Classification" LLM agent to determine which classifications match the codebase, and return a set of matching standards, that is then passed to the existing "Code Reviews" Agent.   

5.5.1 **Processing**
   1. The  `/api/v1/code-reviews` API will be updated to first invoke the "Standards Classification" agent in its async agentic processing.
   2. Process Steps for the "Standards Classification" agent:
	  2.1. Get all classifications from the database to send to the LLM in the next step.
	  2.2. Create an new Anthropic LLM call to examine the code base and return relevant classifications. Use the classifications gathered in the previous step, step 2.1.
	  2.3. For each `standard_set_id` in `standard_sets`, query for all standards whose classifications array is either empty i.e. "universal" or contains a match to the classification from the previous step, step 2.2.
	  2.4. Send the combined list of standards to the "Code Reviews" Agent 
   3. In the "Code Reviews" Agent perform the following steps:
	  3.2. Use the list of relevant standards provided by the "Code Reviews" Agent to create a code review. 
		  Note that this is refactoring the source of a standards, but the rest of the functionality will be the same.
	
## 6. Frontend Requirements

### 6.1 Navigation (✅ Feature Completed)
* **Manage classifications**: New item linking to `/classifications`
* **Manage standards**: New item linking to `/standard-sets`

### 6.2 Classification Manager Pages (✅ Feature Completed)
* **Manage Classifications Page (`/classifications`)**
  * Display a **table** of all classifications from `GET /api/v1/classifications`
	  * **Delete Classification** button for each row of the table (DELETE to `/api/v1/classifications/{id}`)
  * **Add Classification** form (POST to `/api/v1/classifications`)
  * Display **warning** about re-ingestion for changes in classifications

### 6.3 Standards Management (✅ Feature Completed)

1. **Manage Standards Page (`/standard-sets`)**
   * Display a **table** of all standard-sets (from `GET /api/v1/standard-sets`)
     * Columns: Standard-Set Name, Repository URL (opens in new tab), Delete button
     * **Delete** calls `DELETE /api/v1/standard-sets/{id}`
   * **Add New Standard-Set** button -> `/standard-sets/new`

2. **Add New Standard-Set Page (`/standard-sets/new`)**
   * Form fields: `name`, `repository_url`, `custom_prompt`
   * On submit, **POST** to `/api/v1/standard-sets`
   * If success, **redirect** to `/standard-sets/{id}` (the detail page)

3. **Standard Set Detail Page (`/standard-sets/{id}`)**
   * Query **GET** `/api/v1/standard-sets/{id}` on page load
   * Show:
     * Standard-Set Name
     * Repository URL (open in new tab)
     * **Custom Prompt** (hide behind a GDS accordion)
   * **Table** of associated standards, read-only:
     * Columns:
       * Standard Text
       * Comma-separated list of classifications
       * Repository Path (opens in new tab if relevant)

### 6.4 Home Page Updates (✅ Feature Completed)
**Standard-Sets Checkbox List**
**As is:**
- Currently, there is a "Standards" checkbox list containing one hard coded option "Defra software development standards" and two disabled options called "Another Standard".

**To Be:**
* Change the standard checkbox list, so it will now be dynamically built using data from `GET /api/v1/standard-sets`.  The API payload will return an array of standard-sets including the `name` and `_id` which can be used. 

* This is an example payload from `GET /api/v1/standard-sets`: 
```json
[
  {
    "name": "Defra software standards",
    "repository_url": "https://github.com/DEFRA/software-development-standards",
    "custom_prompt": "",
    "_id": "678fabd8c8db99c356e74af9",
    "created_at": "2025-01-21T14:14:48.686000",
    "updated_at": "2025-01-21T14:14:48.686000"
  }
]
``` 
  
* The user will be able select one or more sets to include in their code review. 

* Also add a 'check all' checkbox that checks all the standard-sets to be included in the code review

* When the form is submitted it takes the selected items from the list and puts their standard set ids in an array called `standard_sets` along with `repository_url` into the payload for `POST /api/v1/code-reviews`



### 6.5 Code Review Record Detail Page Updates
**Reports Tabs**

**As Is**
* Currently, there are 3 tabs at the bottom of the page. One with a hard coded value of "Defra Software Development Standards" and two that are disabled with a value of "Another standard"

**To Be**
  * Dynamically populate the tabs using the result from the API `GET api/v1/code-reviews/{id}`. The API payload will include a `compliance_reports` field which contains an array of objects, with each object including a `file` and a `report`
  
  * This is an example payload from `GET api/v1/code-reviews/{id}`
```json
{
  "_id": "678fb3933215e4f9a08091ea",
  "repository_url": "https://github.com/DEFRA/find-techspike-rag",
  "status": "completed",
  "standard_sets": [
    {
      "id": "678fb35e3215e4f9a08091e8",
      "name": "Defra software standards"
    }
  ],
  "compliance_reports": [
    {
      "id": "678fb35e3215e4f9a08091e8",
      "file": "data/codebase/678fb3933215e4f9a08091ea-Defra software standards.md",
      "report": "Here is a compliance report"
    }
  ],
  "created_at": "2025-01-21T14:47:47.509000",
  "updated_at": "2025-01-21T14:48:25.316000"
}
```
    
  * Loop over the array of  `compliance_reports`, and use the `id` to populate the tab title and use `report` to populate the contents


## 7. Data Model & ER Diagram (Conceptual)

```
┌───────────────────┐          ┌────────────────────┐
│    standard-sets  │          │      standards     │
│  _id              │◄──┐ 1..* │  _id               │
│  name             │   │      │  text              │
│  repository_url   │   │      │  repository_path   │
│  custom_prompt    │   │      │  standard_set_id   │
└───────────────────┘   │      │  classification_ids[]         │
                        │      └────────────────────┘
                        │
                        │1..* (a standard-set can have many standards)
                        │
┌───────────────────┐   │
│       classifications        │   │
│  _id              │   │
│  name             │◄──┘M..N (a standard can have many classifications)
└───────────────────┘
```

## 8. Database Schema for Classification System Using References

To implement the classification system with references in MongoDB, we'll establish a many-to-many relationship between standards and classifications. This approach ensures data normalization and efficient querying.

### 8.1 Collections Overview

The system consists of two main collections:

- **Classifications Collection:** Stores individual classifications.
- **Standards Collection:** Stores individual standards, each containing references to associated classifications.

### 8.2 Classifications Collection Schema

Each document in the `classifications` collection represents a unique classification with the following fields:

```json
{
    "_id": ObjectId,    // Unique identifier for the classification
    "name": String      // Name of the classification (e.g., "Python", "Node.js")
}
```

### 8.3 Standards Collection Schema

Each document in the `standards` collection represents an individual standard and includes references to associated classifications:

```json
{
    "_id": ObjectId,            // Unique identifier for the standard
    "text": String,            // Content of the standard
    "repository_path": String,  // Path to the standard in the repository
    "standard_set_id": ObjectId, // Reference to the associated standard-set
    "classification_ids": [ObjectId, ...]  // Array of ObjectId references to associated classifications
}
```

### 8.4 Indexing Strategy

To optimize query performance, especially for operations involving classification associations, implement the following indexes:

#### Classifications Collection

```json
{ "name": 1 }
```

This index ensures efficient retrieval of classifications by name and enforces uniqueness if required.

#### Standards Collection

```json
{ "standard_set_id": 1 }
```

This index facilitates quick access to standards within a specific standard set.

```json
{ "classification_ids": 1 }
```

This index enables efficient querying of standards associated with specific classifications.

### 8.5 Handling Classification Deletions

If a user deletes a classification, it must be removed from each standard that references the classification. The system should handle this dynamically by:

1. Removing the classification's ID from the `classification_ids` array in all affected standards in the `standards` collection.
2. Ensuring that standards with no remaining classifications are correctly handled as universal (if applicable) or flagged for further review.
3. Logging the deletion operation for auditing purposes.

### 8.6 Example Documents

#### Classifications Collection Document

```json
{
    "_id": ObjectId("60c72b2f9af1f8b5d1c8d1e1"),
    "name": "Python"
}
```

#### Standards Collection Document

```json
{
    "_id": ObjectId("60c72b3f9af1f8b5d1c8d1e2"),
    "text": "Standard content here...",
    "repository_path": "/path/to/standard",
    "standard_set_id": ObjectId("60c72b4f9af1f8b5d1c8d1e3"),
    "classification_ids": [
        ObjectId("60c72b2f9af1f8b5d1c8d1e1"),
        ObjectId("60c72b2f9af1f8b5d1c8d1e4")
    ]
}
```

### 8.7 Classification Deletion Workflow Example

1. **Classification Deletion Request:** A user issues a DELETE request for a classification (e.g., `Python`) via the `/api/v1/classifications/{id}` endpoint.
    
2. **Database Update:** The system performs the following operations:
    
    - Query the `standards` collection for documents containing the classification's `_id` in their `classification_ids` array.
    - Remove the classification's `_id` from the `classification_ids` array of all matching standards.
    - Save the updated standards back to the database.
3. **Validation and Logging:**
    
    - Ensure no standards are left with inconsistent `classification_ids` arrays.
    - Log the operation, including the ID of the deleted classification and the affected standards.
4. **User Notification:**
    
    - Notify the user if any standards were affected by the deletion, and if necessary, recommend re-ingesting related standard sets to ensure consistency.

This workflow ensures that classification deletions are consistently propagated through the system, maintaining data integrity and alignment with operational requirements.